{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Beautiful soup for web scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.7/site-packages (2.22.0)\n",
      "Requirement already satisfied: BeautifulSoup4 in /opt/anaconda3/lib/python3.7/site-packages (4.8.0)\n",
      "Requirement already satisfied: fire in /opt/anaconda3/lib/python3.7/site-packages (0.3.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests) (3.0.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /opt/anaconda3/lib/python3.7/site-packages (from BeautifulSoup4) (1.9.3)\n",
      "Requirement already satisfied: termcolor in /opt/anaconda3/lib/python3.7/site-packages (from fire) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from fire) (1.10.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install requests BeautifulSoup4 fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content  #.encode(BeautifulSoup.original_encoding)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors. \n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\n",
    "    \"\"\"\n",
    "    print(e)\n",
    "    \n",
    "def get_elements(url, tag='',search={}, fname=None):\n",
    "    \"\"\"\n",
    "    Downloads a page specified by the url parameter\n",
    "    and returns a list of strings, one per tag element\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(url,str):\n",
    "        response = simple_get(url)\n",
    "    else:\n",
    "        #if already it is a loaded html page\n",
    "        response = url\n",
    "\n",
    "    if response is not None:\n",
    "        html = BeautifulSoup(response, 'html.parser')\n",
    "        \n",
    "        res = []\n",
    "        if tag:    \n",
    "            for li in html.select(tag):\n",
    "                for name in li.text.split('\\n'):\n",
    "                    if len(name) > 0:\n",
    "                        res.append(name.strip())\n",
    "                       \n",
    "                \n",
    "        if search:\n",
    "            soup = html            \n",
    "            \n",
    "            \n",
    "            r = ''\n",
    "            if 'find' in search.keys():\n",
    "                print('findaing',search['find'])\n",
    "                soup = soup.find(**search['find'])\n",
    "                r = soup\n",
    "\n",
    "                \n",
    "            if 'find_all' in search.keys():\n",
    "                print('finding all of',search['find_all'])\n",
    "                r = soup.find_all(**search['find_all'])\n",
    "   \n",
    "            if r:\n",
    "                for x in list(r):\n",
    "                    if len(x) > 0:\n",
    "                        res.extend(x)\n",
    "            \n",
    "        return res\n",
    "\n",
    "    # Raise an exception if we failed to get any data from the url\n",
    "    raise Exception('Error retrieving contents at {}'.format(url))    \n",
    "    \n",
    "    \n",
    "if get_ipython().__class__.__name__ == '__main__':\n",
    "    fire(get_tag_elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most influential Twitter handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = get_elements('https://africafreak.com/100-most-influential-twitter-users-in-africa',tag='h2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting to get Twitter handles from the web scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@Trevornoah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@GarethCliff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@News24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@Julius_S_Malema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>@JamesCopnall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>@AfricaCheck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>@andiMakinana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>@a24media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>@gettleman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            username\n",
       "0        @Trevornoah\n",
       "1       @GarethCliff\n",
       "2               None\n",
       "3            @News24\n",
       "4   @Julius_S_Malema\n",
       "..               ...\n",
       "95     @JamesCopnall\n",
       "96      @AfricaCheck\n",
       "97     @andiMakinana\n",
       "98         @a24media\n",
       "99        @gettleman\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(res1).head(100)\n",
    "df\n",
    "df1 = df[0].str.split('.', expand=True)\n",
    "df2 = df1[1].str.split('(', expand=True)\n",
    "df2[1] = df2[1].str.strip(')')\n",
    "df2.columns = ['name','username']\n",
    "# print(df2)\n",
    "handle = df2[\"username\"]\n",
    "handle1 = pd.DataFrame(handle, columns = ['username'])\n",
    "handle1[::-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
